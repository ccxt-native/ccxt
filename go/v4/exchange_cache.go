package ccxt

// PLEASE DO NOT EDIT THIS FILE MANUALLY UNLESS YOU KNOW WHAT YOU ARE DOING.
// This file provides a minimal Go implementation of the helper caches that
// exist in the JavaScript / C# Web-Socket layers (ArrayCache, ArrayCacheByTimestamp,
// ArrayCacheBySymbolById, ArrayCacheBySymbolBySide).  They satisfy the ArrayCache
// interface declared in exchange.go so that higher-level code can treat them
// uniformly.  The logic is intentionally kept simple – it focuses on correctness
// and type-safety rather than mirroring every micro-optimisation of the JS code.
//
// When the transpiler ports a `pro` exchange it instantiates these caches to
// store streaming Data (trades, ohlcvs, order-books …).  Only two operations
// are required for those flows: Append() and ToArray().  Everything else can be
// added later if/when the need arises.

import "sync"

type Appender interface{ Append(interface{}) }

type CacheType interface {
	*ArrayCache | *ArrayCacheByTimestamp | *ArrayCacheBySymbolById | *ArrayCacheBySymbolBySide | map[string]interface{}

	Append(interface{})
}

type BaseCache struct {
	MaxSize int           `json:"-"`
	Mu      sync.Mutex    `json:"-"`
	Data    []interface{} `json:"data"`
}

func NewBaseCache(MaxSize int) *BaseCache {
	return &BaseCache{MaxSize: MaxSize, Data: make([]interface{}, 0)}
}

func (c *BaseCache) Clear() {
	c.Mu.Lock()
	defer c.Mu.Unlock()
	c.Data = c.Data[:0]
}

func (c *BaseCache) AppendInternal(item interface{}) {
	// helper (no lock)
	if c.MaxSize > 0 && len(c.Data) >= c.MaxSize {
		// drop the oldest element (behaviour identical to JS shift())
		c.Data = c.Data[1:]
	}
	c.Data = append(c.Data, item)
}

// ArrayCache provides O(1) lookup by symbol+id (for orders / trades).
// It also tracks how many new updates arrived but that part is optional for
// now, we expose only the primitives that the rest of the Go code relies on.

type ArrayCache struct {
	*BaseCache

	Hashmap              map[string]map[string]interface{} `json:"-"`
	nestedNewUpdates     bool                              `json:"-"`
	newUpdatesBySymbol   map[string]int                    `json:"-"`
	clearUpdatesBySymbol map[string]bool                   `json:"-"`
	allNewUpdates        int                               `json:"-"`
	clearAllUpdates      bool                              `json:"-"`
}

func NewArrayCache(MaxSize interface{}) *ArrayCache {
	size := 0
	switch v := MaxSize.(type) {
	case int:
		size = v
	case int64:
		size = int(v)
	case float64:
		size = int(v)
	}
	return &ArrayCache{
		BaseCache:            NewBaseCache(size),
		Hashmap:              make(map[string]map[string]interface{}),
		newUpdatesBySymbol:   make(map[string]int),
		clearUpdatesBySymbol: make(map[string]bool),
	}
}

func (c *ArrayCache) Append(item interface{}) {
	// We expect the incoming item to at least expose a "symbol" field; try to
	// extract it when it is a map[string]interface{} – if not present we still
	// store the item, it just won't participate in Hashmap logic.
	var symbol, id string
	if m, ok := item.(map[string]interface{}); ok {
		if s, ok := m["symbol"].(string); ok {
			symbol = s
		}
		// optional id field
		if ident, ok := m["id"].(string); ok {
			id = ident
		}
	}

	// Basic ring-buffer semantics
	c.Mu.Lock()
	defer c.Mu.Unlock()

	if symbol != "" && id != "" {
		// keep reference for O(1) updates / de-dupe
		byId := c.Hashmap[symbol]
		if byId == nil {
			byId = make(map[string]interface{})
			c.Hashmap[symbol] = byId
		}
		if old, exists := byId[id]; exists {
			// overwrite in-place (mirror JS behaviour where the reference is
			// kept alive).  Shallow copy for now.
			if om, ok := old.(map[string]interface{}); ok {
				if nm, ok := item.(map[string]interface{}); ok {
					for k, v := range nm {
						om[k] = v
					}
					item = om // keep the original reference in the array
				}
			}
		} else {
			byId[id] = item
		}
	}

	c.AppendInternal(item)

	// new-update counters (very simplified)
	if symbol != "" {
		c.newUpdatesBySymbol[symbol]++
		c.allNewUpdates++
	}
}

// ToArray implements the ArrayCache interface (defined in exchange.go).
func (c *ArrayCache) ToArray() []interface{} {
	c.Mu.Lock()
	defer c.Mu.Unlock()
	// return a shallow copy to prevent external Mutation
	out := make([]interface{}, len(c.Data))
	copy(out, c.Data)
	return out
}

// GetLimit returns the effective limit according to CCXT logic:
//   - if the caller provided an explicit limit (not nil) – use it;
//   - otherwise, if symbol-specific length is known, use that length;
//   - else fall back to the overall cache size.
//
// The function returns interface{} so the transpiled code that works with
// loosely-typed limits continues to compile.
func (c *ArrayCache) GetLimit(symbol interface{}, limit interface{}) interface{} {
	if limit != nil {
		return limit
	}
	if symbolStr, ok := symbol.(string); ok && symbolStr != "" {
		if byId, exists := c.Hashmap[symbolStr]; exists {
			return len(byId)
		}
	}
	return len(c.ToArray())
}

// ArrayCacheByTimestamp keeps the most recent N entries identified by their
// first element (timestamp). We just need Append and ToArray.

type ArrayCacheByTimestamp struct {
	*BaseCache
	Hashmap map[int64]interface{}
}

func NewArrayCacheByTimestamp(MaxSize interface{}) *ArrayCacheByTimestamp {
	size := 0
	switch v := MaxSize.(type) {
	case int:
		size = v
	case int64:
		size = int(v)
	case float64:
		size = int(v)
	}
	return &ArrayCacheByTimestamp{
		BaseCache: NewBaseCache(size),
		Hashmap:   make(map[int64]interface{}),
	}
}

func (c *ArrayCacheByTimestamp) Append(item interface{}) {
	var ts int64
	if arr, ok := item.([]interface{}); ok && len(arr) > 0 {
		if v, okCast := arr[0].(int64); okCast {
			ts = v
		} else if vF, okF := arr[0].(float64); okF {
			ts = int64(vF)
		}
	}

	c.Mu.Lock()
	defer c.Mu.Unlock()
	if ts != 0 {
		if _, exists := c.Hashmap[ts]; exists {
			c.Hashmap[ts] = item // update existing
			return
		}
		c.Hashmap[ts] = item
	}

	c.AppendInternal(item)
}

func (c *ArrayCacheByTimestamp) ToArray() []interface{} {
	c.Mu.Lock()
	defer c.Mu.Unlock()
	out := make([]interface{}, len(c.Data))
	copy(out, c.Data)
	return out
}

// GetLimit for timestamp cache ignores symbol because entries are not
// symbol-segmented.  It mirrors the same precedence order as ArrayCache.
func (c *ArrayCacheByTimestamp) GetLimit(symbol interface{}, limit interface{}) interface{} {
	if limit != nil {
		return limit
	}
	return len(c.ToArray())
}

// ArrayCacheBySymbolById nests two levels: symbol → id.
// It embeds ArrayCache to reuse its logic.

type ArrayCacheBySymbolById struct{ *ArrayCache }

func NewArrayCacheBySymbolById(optionalArgs ...interface{}) *ArrayCacheBySymbolById {
	maxSize := GetArg(optionalArgs, 0, nil)
	return &ArrayCacheBySymbolById{NewArrayCache(maxSize)}
}

// GetLimit for nested caches delegates to the inner ArrayCache.
func (c *ArrayCacheBySymbolById) GetLimit(symbol interface{}, limit interface{}) interface{} {
	return c.ArrayCache.GetLimit(symbol, limit)
}

// ArrayCacheBySymbolBySide keeps the last update per (symbol, side).

type ArrayCacheBySymbolBySide struct{ *ArrayCache }

func NewArrayCacheBySymbolBySide() *ArrayCacheBySymbolBySide {
	return &ArrayCacheBySymbolBySide{NewArrayCache(nil)}
}

// These specialised caches currently rely on ArrayCache.Append which tracks by
// (symbol, id).  For BySide we override Append to key by side instead.
func (c *ArrayCacheBySymbolBySide) Append(item interface{}) {
	var symbol, side string
	if m, ok := item.(map[string]interface{}); ok {
		if s, ok := m["symbol"].(string); ok {
			symbol = s
		}
		if sd, ok := m["side"].(string); ok {
			side = sd
		}
	}

	c.Mu.Lock()
	defer c.Mu.Unlock()

	if symbol != "" && side != "" {
		bySide := c.Hashmap[symbol]
		if bySide == nil {
			bySide = make(map[string]interface{})
			c.Hashmap[symbol] = bySide
		}
		bySide[side] = item
	}

	c.AppendInternal(item)
}

func (c *ArrayCacheBySymbolBySide) GetLimit(symbol interface{}, limit interface{}) interface{} {
	return c.ArrayCache.GetLimit(symbol, limit)
}
